{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# %pip install kagglehub matplotlib nltk numpy pandas seaborn torch scikit-learn ipywidgets sentence-transformers streamlit nbformat spacy textblob\n",
    "#\n",
    "# try:\n",
    "#     from google.colab import output\n",
    "#     output.enable_custom_widget_manager()\n",
    "# except:\n",
    "#     pass # Not running in Colab"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Why Text Can't Be Input Directly\n",
    "example_text = [\"serendipity\", \"cascade\", \"ephemeral\", \"zenith\", \"labyrinth\"]\n",
    "\n",
    "# Try to perform mathematical operations directly on text\n",
    "try:\n",
    "    result = example_text[0] + example_text[1]\n",
    "    print(f\"Adding words: {example_text[0]} + {example_text[1]} = {result}\")\n",
    "except TypeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "print(\"\"\"\n",
    "Why this doesn't work? \n",
    "\n",
    "1. Text is categorical, not numerical\n",
    "2. No mathematical structure\n",
    "3. Models require inputs for computation\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Show what happens when trying to find similarity\n",
    "print(\"\\nTrying to measure word similarity:\")\n",
    "print(f\"Words: '{example_text[0]}' and '{example_text[1]}'\")\n",
    "print(\"Direct comparison only shows if they're exactly equal:\")\n",
    "print(f\"Are they equal? {example_text[0] == example_text[1]}\")\n",
    "print(\"But we can't measure HOW similar they are!\")\n",
    "\n",
    "# Demonstrate array operations failing\n",
    "print(\"\\nTrying to use in numpy array operations:\")\n",
    "try:\n",
    "    word_array = np.array(example_text)\n",
    "    result = word_array * 2\n",
    "    print(result)\n",
    "except TypeError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 2: Naive Approach - Word to Number Mapping\n",
    "word_to_num = {\n",
    "    \"hello\": 1,\n",
    "    \"hi\": 2,\n",
    "    \"hey\": 3, \n",
    "    \"howdy\": 4,\n",
    "    \"greetings\": 5,\n",
    "    \"welcome\": 6,\n",
    "    \"tree\": 7,\n",
    "    \"flower\": 8,\n",
    "    \"mountain\": 9,\n",
    "    \"river\": 10,\n",
    "    \"ocean\": 11,\n",
    "    \"forest\": 12\n",
    "}\n",
    "\n",
    "def is_greeting(word_num):\n",
    "    return word_num in [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "def is_nature(word_num):\n",
    "    return word_num in [7, 8, 9, 10, 11, 12]\n",
    "\n",
    "def simple_classifier(word_num):\n",
    "    # Simulate a simple model that classifies words\n",
    "    return \"greeting\" if is_greeting(word_num) else \"nature\" if is_nature(word_num) else \"unknown\"\n",
    "\n",
    "# Test the classifier\n",
    "test_words = [\"hello\", \"howdy\", \"tree\", \"ocean\"]\n",
    "print(\"Testing our simple number mapping:\")\n",
    "for word in test_words:\n",
    "    num = word_to_num[word]\n",
    "    classification = simple_classifier(num)\n",
    "    print(f\"{word} (number {num}) -> {classification}\")\n",
    "\n",
    "# Try with an unknown word\n",
    "print(\"\"\"\n",
    "Trying with a new word:\n",
    "'Yo!' -> ???  # 13th most common greeting? https://tandem.net/blog/20-greetings-in-english\n",
    "Problem: Our system breaks with unknown words!\n",
    "\"\"\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(\"\"\"\n",
    "Problems with simple number mapping:\n",
    "1. No relationship between similar words\n",
    "   - 'hello' (1) and 'hi' (3) are similar but their numbers aren't\n",
    "2. No context preservation\n",
    "3. Can't handle new words\n",
    "4. Arbitrary number assignment\n",
    "\"\"\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Cell 4: Introduction to Word Embeddings\n",
    "# Create some simple 2D embeddings for demonstration\n",
    "simple_embeddings = {\n",
    "    \"hello\":     [0.8, 0.9],\n",
    "    \"hi\":        [0.7, 0.8], \n",
    "    \"hey\":       [0.75, 0.85],\n",
    "    \"greetings\": [0.9, 0.7],\n",
    "    \"howdy\":     [0.85, 0.75],\n",
    "    \"world\":     [-0.5, 0.5],\n",
    "    \"earth\":     [-0.6, 0.4],\n",
    "    \"planet\":    [-0.4, 0.6],\n",
    "    \"tree\":      [-0.8, -0.3],\n",
    "    \"forest\":    [-0.9, -0.4], \n",
    "    \"ocean\":     [-0.7, -0.5],\n",
    "    \"yo\":        [0.65, 0.85],\n",
    "}\n",
    "\n",
    "def plot_embeddings(highlight_word=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for word, coords in simple_embeddings.items():\n",
    "        if word == highlight_word:\n",
    "            plt.scatter(coords[0], coords[1], c='red', s=100)\n",
    "            plt.annotate(word, (coords[0], coords[1]), fontsize=12, color='red')\n",
    "        else:\n",
    "            plt.scatter(coords[0], coords[1])\n",
    "            plt.annotate(word, (coords[0], coords[1]), fontsize=10)\n",
    "    \n",
    "    plt.title(\"Simple 2D Word Embeddings\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget to highlight words\n",
    "interact(plot_embeddings, \n",
    "        highlight_word=widgets.Dropdown(\n",
    "            options=[''] + list(simple_embeddings.keys()),\n",
    "            description='Highlight:',\n",
    "            value=''\n",
    "        ))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 5: Similarity in Embedding Space\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "def find_similar_words(word, n=3):\n",
    "    if word not in simple_embeddings:\n",
    "        return \"Word not found in vocabulary\"\n",
    "    \n",
    "    similarities = {}\n",
    "    word_embedding = simple_embeddings[word]\n",
    "    \n",
    "    for other_word, other_embedding in simple_embeddings.items():\n",
    "        if other_word != word:\n",
    "            similarity = cosine_similarity(word_embedding, other_embedding)\n",
    "            similarities[other_word] = similarity\n",
    "    \n",
    "    # Sort by similarity\n",
    "    sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_words[:n]\n",
    "\n",
    "# Interactive similarity finder\n",
    "def show_similarities(word):\n",
    "    similar_words = find_similar_words(word)\n",
    "    print(f\"\\nMost similar words to '{word}':\")\n",
    "    for similar_word, similarity in similar_words:\n",
    "        print(f\"{similar_word}: {similarity:.3f}\")\n",
    "    \n",
    "    # Also show the plot with the word highlighted\n",
    "    plot_embeddings(word)\n",
    "\n",
    "interact(show_similarities, \n",
    "        word=widgets.Dropdown(\n",
    "            options=list(simple_embeddings.keys()),\n",
    "            description='Word:',\n",
    "            value='hello'\n",
    "        ))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "corpus = [\n",
    "    \"dogs and cats are friendly pets\",\n",
    "    \"pets like dogs need daily walks\",\n",
    "    \"cats and kittens love to play\",\n",
    "    \"puppies and dogs enjoy running\",\n",
    "    \"pets bring joy to families\",\n",
    "    \"cats enjoy sleeping in sunshine\", \n",
    "    \"dogs love playing fetch games\",\n",
    "    \"kittens and puppies are cute\",\n",
    "    \"pets need food and water\",\n",
    "    \"animals like cats and dogs make great companions\"\n",
    "]\n",
    "\n",
    "def create_context_matrix(corpus, window_size=2):\n",
    "    # Create vocabulary \n",
    "    words = ' '.join(corpus).split()\n",
    "    vocab = sorted(list(set(words)))\n",
    "    word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    # Initialize context matrix\n",
    "    context_matrix = np.zeros((len(vocab), len(vocab)))\n",
    "    \n",
    "    # Count word co-occurrences with position weighting\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for i, word in enumerate(words):\n",
    "            # Look at surrounding context words\n",
    "            start = max(0, i - window_size)\n",
    "            end = min(len(words), i + window_size + 1)\n",
    "            \n",
    "            for j in range(start, end):\n",
    "                if i != j:\n",
    "                    # Weight by distance - closer words matter more\n",
    "                    distance = abs(i - j)\n",
    "                    weight = 1.0 / distance\n",
    "                    context_matrix[word_to_idx[word]][word_to_idx[words[j]]] += weight\n",
    "    \n",
    "    return context_matrix, vocab\n",
    "\n",
    "def get_similar_words(word, context_matrix, vocab, n=5):\n",
    "    if word not in vocab:\n",
    "        return []\n",
    "    \n",
    "    word_idx = vocab.index(word)\n",
    "    word_vector = context_matrix[word_idx]\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    similarities = []\n",
    "    for i, other_word in enumerate(vocab):\n",
    "        if i != word_idx:\n",
    "            other_vector = context_matrix[i]\n",
    "            similarity = np.dot(word_vector, other_vector) / (np.linalg.norm(word_vector) * np.linalg.norm(other_vector))\n",
    "            similarities.append((other_word, similarity))\n",
    "    \n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "def plot_word_similarities(word, context_matrix, vocab):\n",
    "    similar_words = get_similar_words(word, context_matrix, vocab)\n",
    "    if not similar_words:\n",
    "        print(f\"Word '{word}' not found in vocabulary\")\n",
    "        return\n",
    "        \n",
    "    words, scores = zip(*similar_words)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.barh(words, scores)\n",
    "    plt.title(f\"Words most semantically similar to '{word}'\")\n",
    "    plt.xlabel(\"Similarity score\")\n",
    "    plt.show()\n",
    "\n",
    "# Create and display context matrix\n",
    "context_matrix, vocab = create_context_matrix(corpus)\n",
    "\n",
    "# Show heatmap of relationships\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(context_matrix, xticklabels=vocab, yticklabels=vocab)\n",
    "plt.title(\"Word Context Relationships\")\n",
    "plt.show()\n",
    "\n",
    "# Interactive widget to explore semantic similarities\n",
    "interact(\n",
    "    lambda word: plot_word_similarities(word, context_matrix, vocab),\n",
    "    word=widgets.Dropdown(\n",
    "        options=vocab,\n",
    "        description='Word:',\n",
    "        value='dogs'\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\"\"\n",
    "Key Concepts:\n",
    "1. Words are represented by their contexts (surrounding words)\n",
    "2. Similar words appear in similar contexts\n",
    "3. Position and distance between words matters\n",
    "4. This creates meaningful semantic relationships\n",
    "5. Modern embeddings use similar principles but with neural networks\n",
    "\"\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Initialize the embedding model\n",
    "def load_model():\n",
    "    return SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get embeddings and reduce dimensionality\n",
    "def get_3d_embeddings(texts, model):\n",
    "    # Get embeddings\n",
    "    embeddings = model.encode(texts)\n",
    "\n",
    "    # print the shape of the embeddings\n",
    "    print(embeddings.shape)\n",
    "    \n",
    "    # Reduce to 3D using PCA\n",
    "    pca = PCA(n_components=3)\n",
    "    embeddings_3d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    return embeddings_3d\n",
    "\n",
    "# Function to find similar texts\n",
    "def find_similar_texts(search_text, texts, model, n=5):\n",
    "    # Encode search text and all texts\n",
    "    all_texts = [search_text] + texts\n",
    "    all_embeddings = model.encode(all_texts)\n",
    "    \n",
    "    search_embedding = all_embeddings[0]\n",
    "    text_embeddings = all_embeddings[1:]\n",
    "    \n",
    "    similarities = []\n",
    "    for i, embedding in enumerate(text_embeddings):\n",
    "        similarity = np.dot(search_embedding, embedding) / (np.linalg.norm(search_embedding) * np.linalg.norm(embedding))\n",
    "        similarities.append((texts[i], similarity))\n",
    "    \n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "# Initial example texts\n",
    "default_texts = [\n",
    "    \"hello\", \"hi\", \"hey\", \"greetings\", \n",
    "    \"world\", \"earth\", \"planet\",\n",
    "    \"tree\", \"forest\", \"ocean\"\n",
    "]\n",
    "\n",
    "# Load model\n",
    "model = load_model()\n",
    "\n",
    "# Create widgets\n",
    "text_input = widgets.Text(description='Add text:', placeholder='Enter text here')\n",
    "search_input = widgets.Text(description='Search:', placeholder='Search similar texts')\n",
    "add_button = widgets.Button(description='Add')\n",
    "search_button = widgets.Button(description='Search')\n",
    "\n",
    "# Create output widget for displaying results\n",
    "plot_output = widgets.Output()\n",
    "search_output = widgets.Output()\n",
    "\n",
    "# Current texts list\n",
    "texts = default_texts.copy()\n",
    "\n",
    "def update_plot():\n",
    "    with plot_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Get 3D embeddings\n",
    "        embeddings_3d = get_3d_embeddings(texts, model)\n",
    "\n",
    "        # Create DataFrame for plotting\n",
    "        df = pd.DataFrame({\n",
    "            'text': texts,\n",
    "            'x': embeddings_3d[:, 0],\n",
    "            'y': embeddings_3d[:, 1],\n",
    "            'z': embeddings_3d[:, 2]\n",
    "        })\n",
    "\n",
    "        # Create 3D scatter plot\n",
    "        fig = px.scatter_3d(\n",
    "            df,\n",
    "            x='x',\n",
    "            y='y',\n",
    "            z='z',\n",
    "            text='text',\n",
    "            title='3D Text Embeddings'\n",
    "        )\n",
    "\n",
    "        # Update layout for better visualization\n",
    "        fig.update_traces(\n",
    "            marker=dict(size=8),\n",
    "            textposition='top center'\n",
    "        )\n",
    "\n",
    "        display(fig)\n",
    "\n",
    "def on_add_button_clicked(b):\n",
    "    if text_input.value and text_input.value not in texts:\n",
    "        texts.append(text_input.value)\n",
    "        text_input.value = ''\n",
    "        update_plot()\n",
    "        with search_output:\n",
    "            clear_output()\n",
    "\n",
    "def on_search_button_clicked(b):\n",
    "    with search_output:\n",
    "        clear_output()\n",
    "        if search_input.value:\n",
    "            similar = find_similar_texts(search_input.value, texts, model)\n",
    "            print(\"\\nMost similar texts to '{}':\".format(search_input.value))\n",
    "            for text, similarity in similar:\n",
    "                print(f\"{text}: {similarity:.3f}\")\n",
    "\n",
    "# Connect button clicks to handlers\n",
    "add_button.on_click(on_add_button_clicked)\n",
    "search_button.on_click(on_search_button_clicked)\n",
    "\n",
    "# Display widgets and initial plot\n",
    "display(widgets.HBox([text_input, add_button]))\n",
    "display(widgets.HBox([search_input, search_button]))\n",
    "display(plot_output)\n",
    "display(search_output)\n",
    "\n",
    "# Show initial plot\n",
    "update_plot()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example corpus with diverse examples\n",
    "corpus = [\n",
    "    \"The cat and dog played together in the yard\",\n",
    "    \"The dog and cat were playing in the garden\",  # Similar meaning but different words\n",
    "    \"Machine learning algorithms process data efficiently\",\n",
    "    \"Natural language processing helps computers understand text\",\n",
    "    \"Artificial intelligence is transforming technology\",\n",
    "    \"Deep learning models require large datasets\",\n",
    "    \"The quick brown fox jumps over the lazy dog\",  # Common test sentence\n",
    "    \"AI and ML are revolutionizing industries\",  # Abbreviations vs full words\n",
    "    \"Artificial intelligence and machine learning transform businesses\",  # Same meaning as above\n",
    "    \"The feline and canine were engaging in recreational activities\",  # Formal version of first sentence\n",
    "    \"Data science uses statistical methods\",\n",
    "    \"Statistics and mathematics are used in data analysis\"  # Similar topic, different words\n",
    "]\n",
    "\n",
    "def compare_embeddings(corpus):\n",
    "    # TF-IDF Embeddings with smoothing to prevent divide by zero\n",
    "    tfidf = TfidfVectorizer(smooth_idf=True)  # Add smoothing\n",
    "    tfidf_embeddings = tfidf.fit_transform(corpus).toarray()\n",
    "    \n",
    "    # BERT Embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    bert_embeddings = model.encode(corpus)\n",
    "    \n",
    "    # Calculate similarity matrices with error handling\n",
    "    def cosine_similarity_matrix(embeddings):\n",
    "        # Add small epsilon to prevent division by zero\n",
    "        epsilon = 1e-8\n",
    "        norm = np.linalg.norm(embeddings, axis=1)\n",
    "        norm = np.maximum(norm, epsilon)  # Ensure no zeros in denominator\n",
    "        normalized = embeddings / norm[:, np.newaxis]\n",
    "        return normalized @ normalized.T\n",
    "    \n",
    "    tfidf_sim = cosine_similarity_matrix(tfidf_embeddings)\n",
    "    bert_sim = cosine_similarity_matrix(bert_embeddings)\n",
    "    \n",
    "    # Visualize similarities\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    labels = [text[:10]+'...' for text in corpus]\n",
    "\n",
    "    sns.heatmap(tfidf_sim, ax=ax1, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    ax1.set_title('TF-IDF Similarities\\n(Based on word frequency)')\n",
    "    \n",
    "    sns.heatmap(bert_sim, ax=ax2, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    ax2.set_title('BERT Similarities\\n(Based on semantic meaning)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key differences analysis\n",
    "    print(\"\\nKey Differences Analysis:\")\n",
    "    print(\"\\n1. TF-IDF vs BERT comparison:\")\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(i+1, len(corpus)):\n",
    "            diff = abs(bert_sim[i,j] - tfidf_sim[i,j])\n",
    "            if diff > 0.3:  # Only show significant differences\n",
    "                print(f\"\\nDocuments with different similarity scores:\")\n",
    "                print(f\"Doc {i+1}: {corpus[i]}\")\n",
    "                print(f\"Doc {i+2}: {corpus[j]}\")\n",
    "                print(f\"TF-IDF similarity: {tfidf_sim[i,j]:.3f}\")\n",
    "                print(f\"BERT similarity: {bert_sim[i,j]:.3f}\")\n",
    "    \n",
    "    return tfidf_embeddings, bert_embeddings\n",
    "\n",
    "# Interactive widget to add new sentences\n",
    "def update_corpus(text_widget, _):\n",
    "    new_sentence = text_widget.value\n",
    "    if new_sentence and new_sentence not in corpus:\n",
    "        corpus.append(new_sentence)\n",
    "        compare_embeddings(corpus)\n",
    "        print(\"\\nKey Differences between TF-IDF and BERT:\")\n",
    "        print(\"1. TF-IDF captures word frequency patterns\")\n",
    "        print(\"2. BERT captures semantic relationships\") \n",
    "        print(\"3. BERT understands word context and order\")\n",
    "        print(\"4. TF-IDF is simpler but misses semantic nuances\")\n",
    "        print(\"\\nExample: 'AI' and 'artificial intelligence' would be:\")\n",
    "        print(\"- Different in TF-IDF (different words)\")\n",
    "        print(\"- Similar in BERT (same meaning)\")\n",
    "        text_widget.value = ''  # Clear the input after adding\n",
    "\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter a new sentence to compare...',\n",
    "    description='Add Text:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "add_button = widgets.Button(description='Add')\n",
    "add_button.on_click(lambda b: update_corpus(text_input, b))\n",
    "\n",
    "display(widgets.HBox([text_input, add_button]))\n",
    "\n",
    "# Show initial comparison\n",
    "compare_embeddings(corpus)\n",
    "\n",
    "print(\"\"\"\n",
    "Key Observations:\n",
    "\n",
    "1. TF-IDF Embeddings:\n",
    "   - Based on word frequency statistics\n",
    "   - Ignores word order and context\n",
    "   - Treats similar words as different ('AI' vs 'artificial intelligence')\n",
    "   - Fast and memory-efficient\n",
    "   - Good for keyword extraction and basic document similarity\n",
    "   \n",
    "2. BERT Embeddings:\n",
    "   - Captures contextual meaning\n",
    "   - Understands semantic relationships\n",
    "   - Recognizes similar concepts even with different words\n",
    "   - More computationally intensive\n",
    "   - Better for understanding language nuances\n",
    "   \n",
    "3. When to Use Each:\n",
    "   - TF-IDF: Simple document classification, keyword extraction, search\n",
    "   - BERT: Complex language understanding, semantic similarity, when context matters\n",
    "\"\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Use spaCy for embeddings and TextBlob for sentiment - lightweight and stable\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Install spaCy and download the small English model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Load small English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_embedding(text):\n",
    "    # Get document vector using spaCy\n",
    "    doc = nlp(text)\n",
    "    return doc.vector\n",
    "\n",
    "def get_sentiment(text):\n",
    "    # Get sentiment polarity using TextBlob (-1 to 1)\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def analyze_text(text_input, output_widget):\n",
    "    text = text_input.value\n",
    "    if not text:\n",
    "        return\n",
    "        \n",
    "    # Get embedding and sentiment\n",
    "    embedding = get_embedding(text)\n",
    "\n",
    "    # the embed\n",
    "    sentiment = get_sentiment(text)\n",
    "    \n",
    "    # Clear previous output\n",
    "    output_widget.clear_output()\n",
    "    \n",
    "    with output_widget:\n",
    "        print(f\"\\nAnalysis for: '{text}'\")\n",
    "        print(f\"Sentiment score: {sentiment:.2f}\")\n",
    "        if sentiment > 0:\n",
    "            print(\"This text appears positive\")\n",
    "        elif sentiment < 0:\n",
    "            print(\"This text appears negative\") \n",
    "        else:\n",
    "            print(\"This text appears neutral\")\n",
    "            \n",
    "        print(\"\\nText embedding (first 5 dimensions):\")\n",
    "        print(embedding[:5])\n",
    "\n",
    "# Create widgets\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter text to analyze...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "analyze_button = widgets.Button(description='Analyze')\n",
    "output = widgets.Output()\n",
    "\n",
    "# Wire up the button click\n",
    "analyze_button.on_click(lambda b: analyze_text(text_input, output))\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([text_input, analyze_button]),\n",
    "    output\n",
    "]))\n",
    "\n",
    "print(\"\"\"\n",
    "Try entering different texts to see:\n",
    "1. The sentiment score (-1 to 1)\n",
    "2. A sample of the text embedding vector\n",
    "\n",
    "Example texts to try:\n",
    "- I love this amazing product!\n",
    "- This is the worst experience ever.\n",
    "- The sky is blue.\n",
    "\"\"\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
